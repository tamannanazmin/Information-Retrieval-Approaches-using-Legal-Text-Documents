{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nishat thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "! pip install glove-python-binary\n",
        "from glove import Corpus, Glove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQxv5ZAV1_0b",
        "outputId": "394d1b7e-3f37-426e-e567-87e17411dac2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import library\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiECRnnn2DlT",
        "outputId": "d1caf56a-b737-4517-9389-90903a6801b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "s5JdbMww2FuT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install glove-python-binary\n",
        "from glove import Corpus, Glove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykx1-AxV2H4b",
        "outputId": "86e1f313-21ff-47f8-ba74-e567ef1b13fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "! pip install glove-python-binary\n",
        "from glove import Corpus, Glove\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#from bnlp.corpus import stopwords\n",
        "#from bnlp.corpus.util import remove_stopwords\n",
        "#from bnltk.stemmer import BanglaStemmer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d71Bpu_02J67",
        "outputId": "3d82bd61-d477-405c-bd41-740567b49d2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting glove-python-binary\n",
            "  Downloading glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 16.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.21.6)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##from bnlp.corpus import stopwords\n",
        "#from bnlp.corpus.util import remove_stopwords\n",
        "\n",
        "#from bnltk.stemmer import BanglaStemmer\n",
        "\n",
        "from pandas import read_excel\n",
        "import re\n",
        "from re import sub\n",
        "import multiprocessing\n",
        "\n",
        "import os\n",
        "from time import time \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Dropout,Activation,Embedding,Flatten,Bidirectional,MaxPooling2D, Conv1D, MaxPooling1D\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import h5py\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "-oDKC3B32LoT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "dHrj8I9K2OBD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBbz9N9eyWgW",
        "outputId": "e1f39632-de4d-4e64-e0b0-0675dfed0bc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BIyTbLod1wFE",
        "outputId": "13f49ce5-c207-4af2-af6e-c5c23b42ed80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import glob\\n\\nl = [pd.read_csv(Current_Cases) for Current_Cases in glob.glob(\"/content/drive/MyDrive/nishatThesis/Current_Cases/*.txt\")]\\ndf = pd.concat(l, axis=0)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "'''import glob\n",
        "\n",
        "l = [pd.read_csv(Current_Cases) for Current_Cases in glob.glob(\"/content/drive/MyDrive/nishatThesis/Current_Cases/*.txt\")]\n",
        "df = pd.concat(l, axis=0)'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import pandas as pd\n",
        "list_=pd.read_csv(\"/content/drive/MyDrive/nishatThesis/Current_Cases/*.txt\", header=None)'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XRZZZxhI5Fj7",
        "outputId": "329ab379-b163-4739-b63e-ada60256c380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import pandas as pd\\nlist_=pd.read_csv(\"/content/drive/MyDrive/nishatThesis/Current_Cases/*.txt\", header=None)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import pandas as pd\n",
        "import os\n",
        "\n",
        "file_names = os.listdir('/content/drive/MyDrive/nishatThesis/Current_Cases/')\n",
        "# Create Dictionary for File Name and Text\n",
        "file_name_and_text = {}\n",
        "for file in file_names:\n",
        "    with open('/content/drive/MyDrive/nishatThesis/Current_Cases/' + file, \"r\") as target_file:\n",
        "         file_name_and_text[file] = target_file.read()\n",
        "file_data = (pd.DataFrame.from_dict(file_name_and_text, orient='index')\n",
        "             .reset_index().rename(index = str, columns = {'index': 'file_name', 0: 'text'}))'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "uwzGVRD36epC",
        "outputId": "213d8b0b-b567-44c7-e087-e4abeeb4a3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import pandas as pd\\nimport os\\n\\nfile_names = os.listdir(\\'/content/drive/MyDrive/nishatThesis/Current_Cases/\\')\\n# Create Dictionary for File Name and Text\\nfile_name_and_text = {}\\nfor file in file_names:\\n    with open(\\'/content/drive/MyDrive/nishatThesis/Current_Cases/\\' + file, \"r\") as target_file:\\n         file_name_and_text[file] = target_file.read()\\nfile_data = (pd.DataFrame.from_dict(file_name_and_text, orient=\\'index\\')\\n             .reset_index().rename(index = str, columns = {\\'index\\': \\'file_name\\', 0: \\'text\\'}))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import glob\n",
        "\n",
        "\n",
        "def map_first_lines(file_list):\n",
        "    for file in file_list:\n",
        "        with open(file, 'rt') as fd:\n",
        "            yield fd.readline()\n",
        "\n",
        "\n",
        "def merge_first_lines(file_list, filename='current_case_0001.txt'):\n",
        "    with open(filename, 'w') as f:\n",
        "        for line in map_first_lines(file_list):\n",
        "            f.write(\"%s\\n\" % line)\n",
        "\n",
        "\n",
        "files = glob.glob(\"/content/drive/MyDrive/nishatThesis/Current_Cases/*.txt\")\n",
        "merge_first_lines(files)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "rfxXzhpg9En5",
        "outputId": "6924c816-5786-4c15-f2e7-c99b1f7111cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import glob\\n\\n\\ndef map_first_lines(file_list):\\n    for file in file_list:\\n        with open(file, \\'rt\\') as fd:\\n            yield fd.readline()\\n\\n\\ndef merge_first_lines(file_list, filename=\\'current_case_0001.txt\\'):\\n    with open(filename, \\'w\\') as f:\\n        for line in map_first_lines(file_list):\\n            f.write(\"%s\\n\" % line)\\n\\n\\nfiles = glob.glob(\"/content/drive/MyDrive/nishatThesis/Current_Cases/*.txt\")\\nmerge_first_lines(files)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import pandas as df\n",
        "\n",
        "my_dir_path = \"/content/drive/MyDrive/nishatThesis/Current_Cases\"\n",
        "\n",
        "results = defaultdict(list)\n",
        "for file in Path(my_dir_path).iterdir():\n",
        "    with open(file, \"r\") as file_open:\n",
        "        results[\"file_name\"].append(file.name)\n",
        "        results[\"text\"].append(file_open.read())\n",
        "df = pd.DataFrame(results)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Tpfie20d9sA7",
        "outputId": "23ee4731-dabf-4411-ef49-174f4b6465e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from collections import defaultdict\\nfrom pathlib import Path\\nimport pandas as df\\n\\nmy_dir_path = \"/content/drive/MyDrive/nishatThesis/Current_Cases\"\\n\\nresults = defaultdict(list)\\nfor file in Path(my_dir_path).iterdir():\\n    with open(file, \"r\") as file_open:\\n        results[\"file_name\"].append(file.name)\\n        results[\"text\"].append(file_open.read())\\ndf = pd.DataFrame(results)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import pandas as df\n",
        "\n",
        "main_folder = '/content/drive/MyDrive/nishatThesis/Current_Cases'\n",
        "\n",
        "def get_filename(path):\n",
        "    filenames = []\n",
        "    files = [i.path for i in os.scandir(path) if i.is_file()]\n",
        "\n",
        "    for filename in files:\n",
        "        filename = os.path.basename(filename)\n",
        "        filenames.append(filename)\n",
        "    return filenames\n",
        "\n",
        "files = get_filename(main_folder)\n",
        "#df = pd.DataFrame(files)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''results = defaultdict(list)\n",
        "for file in Path(main_folder).iterdir():\n",
        "    with open(file, \"r\") as file_open:\n",
        "        results[\"files\"].append(file.name)\n",
        "        #results[\"text\"].append(file_open.read())\n",
        "df = pd.DataFrame(results)'''\n",
        "'''with open('some.csv', 'w',  encoding = 'utf8', newline = '') as csv_file:\n",
        "    for _file in files:\n",
        "\n",
        "        file_name = _file\n",
        "        with open(main_folder +'\\\\'+ _file,'r') as f:\n",
        "            text = f.read()\n",
        "\n",
        "            writer = csv.writer(csv_file)\n",
        "            writer.writerow([file_name, text])\n",
        "\n",
        "df = pd.read_csv('some.csv')'''\n",
        "\n",
        "\n",
        " # ...then whatever..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "WWO8xm-F-Xsx",
        "outputId": "d3fc0274-3fc5-41c8-da60-81f9a0a692bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"with open('some.csv', 'w',  encoding = 'utf8', newline = '') as csv_file:\\n    for _file in files:\\n\\n        file_name = _file\\n        with open(main_folder +'\\\\'+ _file,'r') as f:\\n            text = f.read()\\n\\n            writer = csv.writer(csv_file)\\n            writer.writerow([file_name, text])\\n\\ndf = pd.read_csv('some.csv')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwQkTcTOOuNm",
        "outputId": "090beb6d-1094-424e-c720-37049ee072f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['current_case_0041.txt',\n",
              " 'current_case_0141.txt',\n",
              " 'current_case_0075.txt',\n",
              " 'current_case_0050.txt',\n",
              " 'current_case_0139.txt',\n",
              " 'current_case_0192.txt',\n",
              " 'current_case_0164.txt',\n",
              " 'current_case_0028.txt',\n",
              " 'current_case_0105.txt',\n",
              " 'current_case_0084.txt',\n",
              " 'current_case_0161.txt',\n",
              " 'current_case_0156.txt',\n",
              " 'current_case_0162.txt',\n",
              " 'current_case_0017.txt',\n",
              " 'current_case_0061.txt',\n",
              " 'current_case_0136.txt',\n",
              " 'current_case_0063.txt',\n",
              " 'current_case_0138.txt',\n",
              " 'current_case_0085.txt',\n",
              " 'current_case_0104.txt',\n",
              " 'current_case_0053.txt',\n",
              " 'current_case_0151.txt',\n",
              " 'current_case_0097.txt',\n",
              " 'current_case_0129.txt',\n",
              " 'current_case_0130.txt',\n",
              " 'current_case_0047.txt',\n",
              " 'current_case_0180.txt',\n",
              " 'current_case_0190.txt',\n",
              " 'current_case_0135.txt',\n",
              " 'current_case_0194.txt',\n",
              " 'current_case_0126.txt',\n",
              " 'current_case_0179.txt',\n",
              " 'current_case_0008.txt',\n",
              " 'current_case_0007.txt',\n",
              " 'current_case_0030.txt',\n",
              " 'current_case_0199.txt',\n",
              " 'current_case_0112.txt',\n",
              " 'current_case_0121.txt',\n",
              " 'current_case_0145.txt',\n",
              " 'current_case_0031.txt',\n",
              " 'current_case_0113.txt',\n",
              " 'current_case_0042.txt',\n",
              " 'current_case_0027.txt',\n",
              " 'current_case_0102.txt',\n",
              " 'current_case_0034.txt',\n",
              " 'current_case_0046.txt',\n",
              " 'current_case_0154.txt',\n",
              " 'current_case_0160.txt',\n",
              " 'current_case_0183.txt',\n",
              " 'current_case_0158.txt',\n",
              " 'current_case_0146.txt',\n",
              " 'current_case_0079.txt',\n",
              " 'current_case_0033.txt',\n",
              " 'current_case_0124.txt',\n",
              " 'current_case_0083.txt',\n",
              " 'current_case_0032.txt',\n",
              " 'current_case_0026.txt',\n",
              " 'current_case_0175.txt',\n",
              " 'current_case_0181.txt',\n",
              " 'current_case_0038.txt',\n",
              " 'current_case_0094.txt',\n",
              " 'current_case_0147.txt',\n",
              " 'current_case_0019.txt',\n",
              " 'current_case_0188.txt',\n",
              " 'current_case_0200.txt',\n",
              " 'current_case_0187.txt',\n",
              " 'current_case_0099.txt',\n",
              " 'current_case_0006.txt',\n",
              " 'current_case_0023.txt',\n",
              " 'current_case_0155.txt',\n",
              " 'current_case_0076.txt',\n",
              " 'current_case_0140.txt',\n",
              " 'current_case_0081.txt',\n",
              " 'current_case_0057.txt',\n",
              " 'current_case_0176.txt',\n",
              " 'current_case_0091.txt',\n",
              " 'current_case_0153.txt',\n",
              " 'current_case_0092.txt',\n",
              " 'current_case_0177.txt',\n",
              " 'current_case_0003.txt',\n",
              " 'current_case_0025.txt',\n",
              " 'current_case_0114.txt',\n",
              " 'current_case_0010.txt',\n",
              " 'current_case_0172.txt',\n",
              " 'current_case_0166.txt',\n",
              " 'current_case_0134.txt',\n",
              " 'current_case_0128.txt',\n",
              " 'current_case_0086.txt',\n",
              " 'current_case_0196.txt',\n",
              " 'current_case_0070.txt',\n",
              " 'current_case_0044.txt',\n",
              " 'current_case_0024.txt',\n",
              " 'current_case_0064.txt',\n",
              " 'current_case_0096.txt',\n",
              " 'current_case_0065.txt',\n",
              " 'current_case_0082.txt',\n",
              " 'current_case_0107.txt',\n",
              " 'current_case_0012.txt',\n",
              " 'current_case_0073.txt',\n",
              " 'current_case_0125.txt',\n",
              " 'current_case_0159.txt',\n",
              " 'current_case_0043.txt',\n",
              " 'current_case_0142.txt',\n",
              " 'current_case_0195.txt',\n",
              " 'current_case_0132.txt',\n",
              " 'current_case_0037.txt',\n",
              " 'current_case_0004.txt',\n",
              " 'current_case_0018.txt',\n",
              " 'current_case_0167.txt',\n",
              " 'current_case_0069.txt',\n",
              " 'current_case_0150.txt',\n",
              " 'current_case_0088.txt',\n",
              " 'current_case_0143.txt',\n",
              " 'current_case_0100.txt',\n",
              " 'current_case_0039.txt',\n",
              " 'current_case_0020.txt',\n",
              " 'current_case_0078.txt',\n",
              " 'current_case_0009.txt',\n",
              " 'current_case_0011.txt',\n",
              " 'current_case_0074.txt',\n",
              " 'current_case_0133.txt',\n",
              " 'current_case_0123.txt',\n",
              " 'current_case_0171.txt',\n",
              " 'current_case_0185.txt',\n",
              " 'current_case_0109.txt',\n",
              " 'current_case_0198.txt',\n",
              " 'current_case_0174.txt',\n",
              " 'current_case_0108.txt',\n",
              " 'current_case_0165.txt',\n",
              " 'current_case_0184.txt',\n",
              " 'current_case_0045.txt',\n",
              " 'current_case_0101.txt',\n",
              " 'current_case_0087.txt',\n",
              " 'current_case_0029.txt',\n",
              " 'current_case_0005.txt',\n",
              " 'current_case_0182.txt',\n",
              " 'current_case_0072.txt',\n",
              " 'current_case_0127.txt',\n",
              " 'current_case_0090.txt',\n",
              " 'current_case_0144.txt',\n",
              " 'current_case_0049.txt',\n",
              " 'current_case_0106.txt',\n",
              " 'current_case_0168.txt',\n",
              " 'current_case_0120.txt',\n",
              " 'current_case_0117.txt',\n",
              " 'current_case_0197.txt',\n",
              " 'current_case_0173.txt',\n",
              " 'current_case_0131.txt',\n",
              " 'current_case_0169.txt',\n",
              " 'current_case_0058.txt',\n",
              " 'current_case_0052.txt',\n",
              " 'current_case_0068.txt',\n",
              " 'current_case_0149.txt',\n",
              " 'current_case_0178.txt',\n",
              " 'current_case_0067.txt',\n",
              " 'current_case_0148.txt',\n",
              " 'current_case_0137.txt',\n",
              " 'current_case_0189.txt',\n",
              " 'current_case_0157.txt',\n",
              " 'current_case_0170.txt',\n",
              " 'current_case_0040.txt',\n",
              " 'current_case_0056.txt',\n",
              " 'current_case_0152.txt',\n",
              " 'current_case_0055.txt',\n",
              " 'current_case_0095.txt',\n",
              " 'current_case_0060.txt',\n",
              " 'current_case_0098.txt',\n",
              " 'current_case_0111.txt',\n",
              " 'current_case_0193.txt',\n",
              " 'current_case_0093.txt',\n",
              " 'current_case_0119.txt',\n",
              " 'current_case_0103.txt',\n",
              " 'current_case_0080.txt',\n",
              " 'current_case_0035.txt',\n",
              " 'current_case_0066.txt',\n",
              " 'current_case_0116.txt',\n",
              " 'current_case_0059.txt',\n",
              " 'current_case_0089.txt',\n",
              " 'current_case_0077.txt',\n",
              " 'current_case_0163.txt',\n",
              " 'current_case_0051.txt',\n",
              " 'current_case_0048.txt',\n",
              " 'current_case_0118.txt',\n",
              " 'current_case_0036.txt',\n",
              " 'current_case_0186.txt',\n",
              " 'current_case_0015.txt',\n",
              " 'current_case_0016.txt',\n",
              " 'current_case_0071.txt',\n",
              " 'current_case_0062.txt',\n",
              " 'current_case_0115.txt',\n",
              " 'current_case_0110.txt',\n",
              " 'current_case_0022.txt',\n",
              " 'current_case_0054.txt',\n",
              " 'current_case_0013.txt',\n",
              " 'current_case_0122.txt',\n",
              " 'current_case_0191.txt',\n",
              " 'current_case_0014.txt',\n",
              " 'current_case_0021.txt',\n",
              " 'current_case_0001.txt',\n",
              " 'current_case_0002.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#files"
      ],
      "metadata": {
        "id": "loe2y-KfDVcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.sort(key = str)\n",
        "# printing result\n",
        "print ((files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH6fgEQvEAb5",
        "outputId": "37b2a51c-c4c2-45d2-c5f2-9089cc0af394"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['current_case_0001.txt', 'current_case_0002.txt', 'current_case_0003.txt', 'current_case_0004.txt', 'current_case_0005.txt', 'current_case_0006.txt', 'current_case_0007.txt', 'current_case_0008.txt', 'current_case_0009.txt', 'current_case_0010.txt', 'current_case_0011.txt', 'current_case_0012.txt', 'current_case_0013.txt', 'current_case_0014.txt', 'current_case_0015.txt', 'current_case_0016.txt', 'current_case_0017.txt', 'current_case_0018.txt', 'current_case_0019.txt', 'current_case_0020.txt', 'current_case_0021.txt', 'current_case_0022.txt', 'current_case_0023.txt', 'current_case_0024.txt', 'current_case_0025.txt', 'current_case_0026.txt', 'current_case_0027.txt', 'current_case_0028.txt', 'current_case_0029.txt', 'current_case_0030.txt', 'current_case_0031.txt', 'current_case_0032.txt', 'current_case_0033.txt', 'current_case_0034.txt', 'current_case_0035.txt', 'current_case_0036.txt', 'current_case_0037.txt', 'current_case_0038.txt', 'current_case_0039.txt', 'current_case_0040.txt', 'current_case_0041.txt', 'current_case_0042.txt', 'current_case_0043.txt', 'current_case_0044.txt', 'current_case_0045.txt', 'current_case_0046.txt', 'current_case_0047.txt', 'current_case_0048.txt', 'current_case_0049.txt', 'current_case_0050.txt', 'current_case_0051.txt', 'current_case_0052.txt', 'current_case_0053.txt', 'current_case_0054.txt', 'current_case_0055.txt', 'current_case_0056.txt', 'current_case_0057.txt', 'current_case_0058.txt', 'current_case_0059.txt', 'current_case_0060.txt', 'current_case_0061.txt', 'current_case_0062.txt', 'current_case_0063.txt', 'current_case_0064.txt', 'current_case_0065.txt', 'current_case_0066.txt', 'current_case_0067.txt', 'current_case_0068.txt', 'current_case_0069.txt', 'current_case_0070.txt', 'current_case_0071.txt', 'current_case_0072.txt', 'current_case_0073.txt', 'current_case_0074.txt', 'current_case_0075.txt', 'current_case_0076.txt', 'current_case_0077.txt', 'current_case_0078.txt', 'current_case_0079.txt', 'current_case_0080.txt', 'current_case_0081.txt', 'current_case_0082.txt', 'current_case_0083.txt', 'current_case_0084.txt', 'current_case_0085.txt', 'current_case_0086.txt', 'current_case_0087.txt', 'current_case_0088.txt', 'current_case_0089.txt', 'current_case_0090.txt', 'current_case_0091.txt', 'current_case_0092.txt', 'current_case_0093.txt', 'current_case_0094.txt', 'current_case_0095.txt', 'current_case_0096.txt', 'current_case_0097.txt', 'current_case_0098.txt', 'current_case_0099.txt', 'current_case_0100.txt', 'current_case_0101.txt', 'current_case_0102.txt', 'current_case_0103.txt', 'current_case_0104.txt', 'current_case_0105.txt', 'current_case_0106.txt', 'current_case_0107.txt', 'current_case_0108.txt', 'current_case_0109.txt', 'current_case_0110.txt', 'current_case_0111.txt', 'current_case_0112.txt', 'current_case_0113.txt', 'current_case_0114.txt', 'current_case_0115.txt', 'current_case_0116.txt', 'current_case_0117.txt', 'current_case_0118.txt', 'current_case_0119.txt', 'current_case_0120.txt', 'current_case_0121.txt', 'current_case_0122.txt', 'current_case_0123.txt', 'current_case_0124.txt', 'current_case_0125.txt', 'current_case_0126.txt', 'current_case_0127.txt', 'current_case_0128.txt', 'current_case_0129.txt', 'current_case_0130.txt', 'current_case_0131.txt', 'current_case_0132.txt', 'current_case_0133.txt', 'current_case_0134.txt', 'current_case_0135.txt', 'current_case_0136.txt', 'current_case_0137.txt', 'current_case_0138.txt', 'current_case_0139.txt', 'current_case_0140.txt', 'current_case_0141.txt', 'current_case_0142.txt', 'current_case_0143.txt', 'current_case_0144.txt', 'current_case_0145.txt', 'current_case_0146.txt', 'current_case_0147.txt', 'current_case_0148.txt', 'current_case_0149.txt', 'current_case_0150.txt', 'current_case_0151.txt', 'current_case_0152.txt', 'current_case_0153.txt', 'current_case_0154.txt', 'current_case_0155.txt', 'current_case_0156.txt', 'current_case_0157.txt', 'current_case_0158.txt', 'current_case_0159.txt', 'current_case_0160.txt', 'current_case_0161.txt', 'current_case_0162.txt', 'current_case_0163.txt', 'current_case_0164.txt', 'current_case_0165.txt', 'current_case_0166.txt', 'current_case_0167.txt', 'current_case_0168.txt', 'current_case_0169.txt', 'current_case_0170.txt', 'current_case_0171.txt', 'current_case_0172.txt', 'current_case_0173.txt', 'current_case_0174.txt', 'current_case_0175.txt', 'current_case_0176.txt', 'current_case_0177.txt', 'current_case_0178.txt', 'current_case_0179.txt', 'current_case_0180.txt', 'current_case_0181.txt', 'current_case_0182.txt', 'current_case_0183.txt', 'current_case_0184.txt', 'current_case_0185.txt', 'current_case_0186.txt', 'current_case_0187.txt', 'current_case_0188.txt', 'current_case_0189.txt', 'current_case_0190.txt', 'current_case_0191.txt', 'current_case_0192.txt', 'current_case_0193.txt', 'current_case_0194.txt', 'current_case_0195.txt', 'current_case_0196.txt', 'current_case_0197.txt', 'current_case_0198.txt', 'current_case_0199.txt', 'current_case_0200.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''data_list=[]\n",
        "max=0\n",
        "for i in range(len(files)):\n",
        "  data_list.append(pd.read_fwf('/content/drive/MyDrive/nishatThesis/Current_Cases/'+ files[i],header = None, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, error_bad_lines=False,encoding='cp1252'))\n",
        "  if(max<len(data_list[i])):\n",
        "    max=len(data_list[i])\n",
        "print(max)\n",
        "  #corpus.append(d)\n",
        "  #df = pd.DataFrame (files, columns = ['current_case'])'''"
      ],
      "metadata": {
        "id": "h4ewWhugBId6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "19744744-2063-4a25-e3ad-fcf9d1bf5304"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data_list=[]\\nmax=0\\nfor i in range(len(files)):\\n  data_list.append(pd.read_fwf(\\'/content/drive/MyDrive/nishatThesis/Current_Cases/\\'+ files[i],header = None, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, error_bad_lines=False,encoding=\\'cp1252\\'))\\n  if(max<len(data_list[i])):\\n    max=len(data_list[i])\\nprint(max)\\n  #corpus.append(d)\\n  #df = pd.DataFrame (files, columns = [\\'current_case\\'])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "data_list=[]\n",
        "max=0\n",
        "j=0\n",
        "for i in range(len(files)):\n",
        "  file_path='/content/drive/MyDrive/nishatThesis/Current_Cases/'+ files[i]\n",
        "  txt= Path(file_path).read_text(encoding='cp1252')\n",
        "  data_list.append(txt)\n",
        "  if(max<len(data_list[i])):\n",
        "    max=len(data_list[i])\n",
        "    j=i\n",
        "print(max,j)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5njc7v2KRlZF",
        "outputId": "3e0ba4b1-a2ed-4cde-8184-54a5bb8bf0ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "264303 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(len(data_list[58]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "MG9GfJZLlvv5",
        "outputId": "7ecbee15-6d12-4fba-a27d-ec68bbf3abdf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "264303"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''dataset = pd.DataFrame(data_list, columns = ['current_case'])\n",
        "dataset.to_csv('result.csv')'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "dzGaN36wF2RX",
        "outputId": "8ef54408-5b51-4176-d18a-1b10e18b38a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"dataset = pd.DataFrame(data_list, columns = ['current_case'])\\ndataset.to_csv('result.csv')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!pip install xlsxwriter\n",
        "dataset.to_excel('bb.xlsx', index=False, engine='xlsxwriter')'''"
      ],
      "metadata": {
        "id": "2OEIgqxTILfB",
        "outputId": "a050a3a0-aa2f-4d66-9e65-ba030cb8220d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip install xlsxwriter\\ndataset.to_excel('bb.xlsx', index=False, engine='xlsxwriter')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from google.colab import files\n",
        "dataset.to_csv('filename.csv') \n",
        "dataset.download('filename.csv')'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "iMA2Mwc84sAC",
        "outputId": "8240adcb-9071-4e24-b8e1-f9205fa91701"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from google.colab import files\\ndataset.to_csv('filename.csv') \\ndataset.download('filename.csv')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset['current_case']"
      ],
      "metadata": {
        "id": "f0B95aNenPU5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''#data_list.values.tolist()\n",
        "print(type(data_list))'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bIVvrnWvpWbI",
        "outputId": "b55fd054-4954-49bc-8807-e360a73e2ec9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#data_list.values.tolist()\\nprint(type(data_list))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " '''dataset['current_case']= dataset['current_case'].astype(str)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kYWe0Tw_riq-",
        "outputId": "93b18a36-de14-4334-f2cc-9b6cbdadc978"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"dataset['current_case']= dataset['current_case'].astype(str)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning the texts\n",
        "import re\n",
        "corpus=[]\n",
        "max=0\n",
        "j=0\n",
        "for i in range(len(data_list)):\n",
        "    review=re.sub('[^a-zA-Z0-9]',' ',data_list[i])\n",
        "    review=review.lower()\n",
        "    review=str(review)\n",
        "    review=review.split()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    review = [w for w in review if not w.lower() in stop_words]\n",
        "    corpus.append(review)\n",
        "    if(max<len(review)):\n",
        "      max=len(review)\n",
        "      j=i\n",
        "print(max,j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipp2fhAKiVtp",
        "outputId": "c0ff6a70-3be8-487c-ee7a-341f1aa5f22f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24296 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#corpus"
      ],
      "metadata": {
        "id": "3PIGQdl4r8Hu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset.rename( columns={0:'current_case'}, inplace=True )"
      ],
      "metadata": {
        "id": "-vB76VUCGGs2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}